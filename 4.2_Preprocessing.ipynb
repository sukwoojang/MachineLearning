{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 레이블 [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/'\n",
    "                     'ml/machine-learning-databases/'\n",
    "                     'wine/wine.data', header=None)\n",
    "df_wine.columns = ['Class label','Alcohol','Malic acid','Ash',\n",
    "                  'Alcalinity of ash', 'Magnesium',' Total phenols',\n",
    "                  'Flavanoids', 'Nonflavanoid phenols','Proanthocyanins',\n",
    "                  'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',\n",
    "                  'Proline']\n",
    "print('클래스 레이블',np.unique(df_wine['Class label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df_wine.iloc[:,1:].values, df_wine.iloc[:,0].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특성 스케일 맞추기\n",
    "특성 스케일 조정은 전처리 파이프라인에서 잊어버리기 쉽지만 아주 중요한 단계이다. 결정 트리와 랜덤 포레스트는 특성 스케일 조정에 대해 걱정할 필요가 없는 몇 안 되는 머신 러닝 알고리즘 중 하나이다. 하지만 대부분 머신러닝과 최적화 알고리즘은 특성의 스케일이 같을 때 훨씬 성능이 좋다.\n",
    "\n",
    "* 정규화(normalization) : 대부분 정규화는 특성의 스케일을 [0,1]범위에 맞추는 것을 의미. 즉, 최소-최대 스케일 변환의 특별한 경우이다.\n",
    "* 최소-최대 스케일 변환(min-max scailing):\n",
    "$$ x^{(i)}_{norm} = \\frac{{x^{(i)}-x_{min}}{x_{max}-x_{min}} $$\n",
    "* 표준화(standardization) : 특성의 평균을 0에 맞추고 표준 편차를 1로 만들어 정규 분포와 같은 특징을 가지도록 만드는 것. 이상치 정보가 유지되기 때문에 제한된 범위로 데이터를 조정하는 최소-최대 스케일 변환에 비해 알고리즘이 이상치에 덜 민감하다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "X_train_norm = mms.fit_transform(X_train)\n",
    "X_test_norm = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표준화: [-1.46385011 -0.87831007 -0.29277002  0.29277002  0.87831007  1.46385011]\n",
      "정규화: [0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "ex = np.array([0 ,1 ,2, 3, 4, 5])\n",
    "print('표준화:', (ex - ex.mean()) / ex.std())\n",
    "print('정규화:', (ex - ex.min()) / (ex.max() - ex.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유용한 특성 선택\n",
    "\n",
    "* 과대적합 (overfitting) : 모델이 테스트 세트보다 훈련 세트에서 성능이 높다면 과대적합에 대한 강력한 신호이다. 모델 분산이 크고 과대적합의 이유는 주어진 훈련 데이터에 비해 모델이 너무 복잡하기 때문이다. 일반화 오차를 감소시키기 위해 많이 사용하는 방법은 다음과 같다.\n",
    "    * 더 많은 훈련 데이터를 모은다.\n",
    "    * 규제를 통해 복잡도를 제한한다.\n",
    "    * 파라미터 개수가 적은 간단한 모델을 선택한다.\n",
    "    * 데이터 차원을 줄인다.<br><br>\n",
    "    \n",
    "* 모델 복잡도 제한을 위한 L1 규제와 L2 규제 :\n",
    "    * L2 규제 : $ L2:||w||^2_2 = \\sum\\limits_{j=1}^{m}w^2_j $\n",
    "    * L1 규제 : $ L1:||w||_1 = \\sum\\limits_{j=1}^{m}|w_j| $\n",
    "    (L2 규제와 대조적으로 L1 규제는 보통 희소한 특성 벡터를 만든다. 즉, 대부분의 특성 가중치가 0이 되는데 실제로 관련 없는 특성이 많은 고차원 데이터셋일 경우 이런 희소성이 도움이 될 수 있다.)\n",
    "    <br><br>\n",
    "* L2 규제의 기하학적 해석\n",
    "* L1 규제를 사용한 희소성 <font color=red>규제에 대해서 확실하게 조사하고공부하고 정리해놓을 것</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
